# %% [markdown]
# # 이미지 식별 머신을 위한 데이터를 준비한다.

# %% [markdown]
# ## 필요한 라이브러리를 불러 온다.

# %%
# pip install torch
# pip install torchvision

# 데이터 플로팅 라이브러리
import matplotlib.pyplot as plt
# 숫자 처리 라이브러리
import numpy as np
# 딥러닝을 위한 파이토치 라이브러리
import torch
from torch import nn, optim
# 토치비전 라이브러리
import torchvision
from torchvision import datasets, transforms, models
# 이미지 처리 라이브러리 (PIL, pillow)
from PIL import Image
# 주피터 노트북에서 plot이 보이도록 설정
%matplotlib inline
%config InlineBackend.figure_format = 'retina'

# %% [markdown]
# ## 데이터 디렉토리, 분할 비율, 변환 방법을 설정한다.

# %%
# 이미지 데이터가 있는 디렉토리와 데이터 세트 분할 비율(valid_size)을 정한다.
data_dir = './data'
valid_size = 0.2

# 이미지 데이터를 ResNet50에서 다룰 수 있도록 변환시키는 방법을 정한다. (t_transforms)
t_transforms = transforms.Compose([
               transforms.RandomResizedCrop(224),
               transforms.Resize(224),
               transforms.ToTensor()
])
# convert image size to 224x224 for ResNet50 after crop

# %% [markdown]
# ### (확인) 변환 방법을 출력하여 확인해 본다.

# %%
# 설정한 이미지 데이터 변환 방법을 출력하여 확인한다.
print(t_transforms)

# %% [markdown]
# ## 데이터를 로딩 함수를 작성한다.

# %% [markdown]
# ### (연습) trainloader와 testloader를 만들어 본다.

# %% [markdown]
# #### 1. 학습 데이터 세트 및 테스트 데이터 세트의 디렉토리 및 변환 방식을 지정한다.

# %%
# datasets.ImageFolder를 사용해서 학습 데이터(train_data)와 테스트 데이터(test_data)를 만든다.
# make train_data and test_data using datasets.ImageFolder
train_data = datasets.ImageFolder(data_dir, transform=t_transforms)
test_data = datasets.ImageFolder(data_dir, transform=t_transforms)

# 학습 데이터의 형식을 확인한다.
print(train_data)

# 학습 데이터와 테스트 데이터의 길이를 확인한다.
print(len(train_data), len(test_data))


# %% [markdown]
# #### 2. 데이터세트를 섞기 위해, 우선 인덱스를 만들어 랜덤하게 섞는다.

# %%
# train_data 사이즈만큼의 정수값을 갖는 인덱스 리스트(indices)를 만들고 확인한다.
num_train = len(train_data)
indices = list(range(num_train))
print(indices)

# 인덱스 리스트를 랜덤하게 섞고 확인한다.
np.random.shuffle(indices)
print(indices)


# %% [markdown]
# #### 3. 분할 비율(valid_size)에 따른 지점의 인덱스 값(split)을 계산한다.

# %%
# 분할 비율(valid_size)에 해당하는 인덱스를 계산하고 확인해 본다.
split = int(np.floor(num_train*valid_size))
print(split)

# %% [markdown]
# #### 4. split을 기준으로 학습 데이터 인덱스 리스트와 테스트 인덱스 리스트로 나눈다.

# %%
# 학습 데이터 인덱스 리스트 및 테스트 인덱스 리스트를 만들고 확인해 본다.
train_idx, test_idx = indices[split:], indices[:split]

print(train_idx)
print(test_idx)


# %% [markdown]
# #### 5. 데이터 세트들의 샘플러 및 로더를 만들고 확인한다.

# %%
# 데이터 샘플링 방식(SubsetRandomSampler)을 지정한다
from torch.utils.data.sampler import SubsetRandomSampler
train_sampler = SubsetRandomSampler(train_idx)
test_sampler = SubsetRandomSampler(test_idx)

# 데이터 로딩을 위한 loader를 만든다. (sampler, 배치 사이즈 등 지정)
trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)
testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=16)

# 학습 loader와 테스트 loader의 class들을 출력하여 확인한다.
print(trainloader.dataset.classes)
print(testloader.dataset.classes)

# %% [markdown]
# ### 코드들을 묶어서 load_split_train_test() 함수를 만든다.

# %%
# 위의 코드들을 묶어서 load_split_train_test() 함수를 만든다. (입력 : 데이터 디렉토리, 분할 비율) (출력 : 학습 데이터 로더, 테스트 데이터 로더)

def load_split_train_test(data_dir, valid_size) :
    t_transforms = transforms.Compose([
               transforms.RandomResizedCrop(224),
               transforms.Resize(224),
               transforms.ToTensor()
               ])
    
    train_data = datasets.ImageFolder(data_dir, transform=t_transforms)
    test_data = datasets.ImageFolder(data_dir, transform=t_transforms)
    num_train = len(train_data)
    indices = list(range(num_train))

    np.random.shuffle(indices)
    split = int(np.floor(num_train*valid_size))
    train_idx, test_idx = indices[split:], indices[:split]
    from torch.utils.data.sampler import SubsetRandomSampler

    train_sampler = SubsetRandomSampler(train_idx)
    test_sampler = SubsetRandomSampler(test_idx)

    trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)
    testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=16)

    return trainloader, testloader

# %% [markdown]
# ### load_split_train_test() 함수를 이용하여 trainloader, testloader를 생성한다.

# %%
# load_split_train_test() 함수를 이용하여 trainloader와 testloader를 만들고 확인한다.
trainloader, testloader = load_split_train_test(data_dir, 0.2)

print(trainloader.dataset.classes)
print(testloader.dataset.classes)


# %% [markdown]
# ## 이미지 데이터 샘플들을 살펴본다.

# %% [markdown]
# ### 임의의 데이터를 로딩한 후 이미지와 레이블을 반환하는 get_random_images() 함수를 만든다.

# %%
def get_random_images(num) :
    
    data = datasets.ImageFolder(data_dir, transform=t_transforms)
    indices = list(range(len(data)))
    np.random.shuffle(indices)
    idx = indices[:num]

    from torch.utils.data.sampler import SubsetRandomSampler
    sampler = SubsetRandomSampler(idx)
    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)

    dataiter = iter(loader)
    images, labels = next(dataiter)

    return images, labels
    

# %% [markdown]
# ### 임의 선택한 이미지를 표시해 본다.

# %%
# 5개의 이미지와 레이블을 랜덤하게 가져온다.
images, labels = get_random_images(5)

# 픽셀 배열을 PIL 형식의 이미지로 변환하고 이미지 크기를 지정한다.
to_pil = transforms.ToPILImage()
fig = plt.figure(figsize=(20,20))

# 학습 데이터의 class 리스트를 얻는다.
classes = trainloader.dataset.classes

# 이미지를 표시하기 위한 설정을 한다.
for ii in range(len(images)) :
    image = to_pil(images[ii])
    sub = fig.add_subplot(1, len(images), ii+1)
    index = labels[ii].item()
    sub.set_title(classes[index])
    plt.axis('off')
    plt.imshow(image)

# 주피터 노트북에 이미지를 표시한다.
plt.show()


# %% [markdown]
# # ResNet50 모델을 가져와 FCL(Fully Connected Layer)을 수정한다.

# %% [markdown]
# ## Compute device를 정한다(CPU or GPU)

# %%
# compute device를 정하고 확인한다.
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

# %% [markdown]
# ## 사전학습된 ResNet50 모델을 지정한다.

# %%
# resnet50 모델을 pretrained=True로 설정한다.
model = models.resnet50(pretrained=True)

# %% [markdown]
# ### (확인) 수정 전의 ResNet50 모델을 확인해 본다. 

# %%
print(model)

# %% [markdown]
# ## FCL을 수정한다.(뉴런 구축, 신경망 연결, FCL의 layer 설정 등)

# %%
# 모든 신경망 구축: 전이학습을 위해 모델의 가중치를 freeze 한다.
for param in model.parameters():
    param.requires_grad = False

# 뉴런들을 연결하여 신경망을 생성한다.
model.fc = nn.Sequential(nn.Linear(2048, 512),
                         nn.ReLU(),
                         nn.Dropout(0.2),
                         nn.Linear(512, 2),
                         nn.LogSoftmax(dim=1))

# 손실함수를 Cross entropy loss 함수로 지정한다.
criterion = nn.NLLLoss()

# optimizer를 Adam으로 지정한다.
optimizer = optim.Adam(model.fc.parameters(), lr=0.003)

# 신경망을 compute device로 보낸다.
model.to(device)

# 종료 여부를 출력한다.
print('done!')


# %% [markdown]
# ### (확인) FCL을 확인해 본다.

# %%
print(model.fc)

# %% [markdown]
# # 모델의 FCL을 학습시키고 테스트 한다.

# %% [markdown]
# ## 모델 학습/검증을 위한 변수를 설정한다.

# %%
# 에폭 및 출력 간격을 설정한다.
epochs = 10
print_every = 5

# 손실 변수들을 초기화 한다.
running_loss = 0
train_losses, test_losses = [], []

# 현재의 학습 단계를 표현하는 steps 변수를 0으로 초기화 한다.
steps = 0

# %% [markdown]
# ## 설정한 에폭만큼 모델을 학습시키며 검증/평가 한다.

# %%
# 설정한 횟수만큼 학습 후 테스트 및 평가해 본다.
for epoch in range(epochs):
    # 에폭을 count 한다.
    epoch += 1
    # trainloader로부터 모든 이미지와 레이블을 로드한다.
    for inputs, labels in trainloader:
        # 학습 단계를 count 하고 출력한다.
        steps += 1
        print('Training step', steps)

        # 입력 데이터(이미지, 레이블)를 device로 보낸다.
        inputs, labels = inputs.to(device), labels.to(device)

        # 각 미니 배치마다 학습된 기울기 값을 초기화 한다.
        optimizer.zero_grad()  # 이전 학습된 값의 영향을 제거

        # 입력 데이터로 순전파를 수행하고 로그 확률을 얻는다.
        logps = model.forward(inputs)

        # 손실(loss) 값을 계산한다.
        loss = criterion(logps, labels)

        # 손실값을 이용하여 gradient를 update한다.
        loss.backward()

        # optimizer를 이용하여 설정된 optimizer로 파라미터를 update한다.
        optimizer.step()

        # 손실값을 누적 계산한다.
        running_loss += loss.item()

        # 학습 단계 5회마다 모델을 테스트/평가 한다.
        if steps % print_every == 0:
            # 손실값과 정확도 변수를 초기화 한다.
            test_loss = 0
            accuracy = 0

            # 모델 평가 모드로 전환한다.
            model.eval()

            # 모델 평가 시 gradient를 계산하지 않도록 한다.
            with torch.no_grad():
                # testloader로부터 모든 이미지와 레이블을 로드한다.
                for inputs, labels in testloader:
                    # 입력 데이터(이미지, 레이블)를 device로 보낸다.
                    inputs, labels = inputs.to(device), labels.to(device)

                    # 입력 데이터로 순전파를 수행하고 로그 확률을 얻는다.
                    logps = model.forward(inputs)

                    # 손실(loss) 값을 계산한다.
                    batch_loss = criterion(logps, labels)

                    # 손실값을 누적시킨다.
                    test_loss += batch_loss.item()

                    # 로그 확률로부터 진짜 확률값을 계산한다.
                    ps = torch.exp(logps)

                    # 가장 큰 확률값과 class를 얻는다. (topk : k번째로 큰 값)
                    top_p, top_class = ps.topk(1, dim=1)

                    # 예측된 top_class와 동일한 형태로 label을 변경한 후 같은 값들을 얻는다.
                    equals = top_class == labels.view(*top_class.shape)

                    # equals를 float 텐서로 바꾼 후 평균 정확도를 누적 계산한다.
                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()

            # 학습 손실값과 테스트 손실값을 추가한다.
            train_losses.append(running_loss/len(trainloader))
            test_losses.append(test_loss/len(testloader))

            # 학습 손실값, 테스트 손실값, 테스트 정확도를 출력한다.
            print("Epoch {}/{}.. ".format(epoch, epochs),
                "Train Loss: {:.3f}.. ".format(running_loss/print_every),
                "Test Loss: {:.3f}.. ".format(test_loss/len(testloader)),
                "Test Accuracy: {:.3f}".format(accuracy/len(testloader)))

            # running_loss 값을 초기화 한다.
            running_loss = 0

            # 모델 학습 모드로 전환한다.
            model.train()
            break


# %% [markdown]
# ### (확인) 학습 손실값과 테스트 손실값을 그래프로 확인한다.

# %%
%matplotlib inline
%config InlineBackend.figure_format='retina'

plt.plot(train_losses, label='training loss')
plt.plot(test_losses, label='Validation loss')
plt.legend(frameon=False)

# in this graph, what is x-axis? y-axis?
# x-axis: epoch
# y-axis: loss

# %% [markdown]
# # 학습/테스트 완료된 모델을 저장한다.

# %%
# 추후 로드하여 사용할 수 있도록 학습/테스트 완료된 모델을 저장한다.
torch.save(model, 'moonrockmodel.pth')

# %% [markdown]
# # 완성된 모델을 사용하여 예측한다.

# %% [markdown]
# ## 저장한 모델을 불러온다.

# %%
# 저장한 모델을 불러온다.


# %% [markdown]
# ### (확인) 불러온 모델을 확인해 본다.

# %%


# %% [markdown]
# ## 이미지 예측을 위해 predict_image() 함수를 만든다.

# %%


# %% [markdown]
# ## 5개의 이미지를 임의로 가져와 예측해 본다.

# %%



